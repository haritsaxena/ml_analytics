{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "  \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Insurance/insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introduce ‘impurities’ in this dataset\n",
    "np.random.seed(0) # for reproducibility \n",
    "for _ in range(10): \n",
    "    r = np.random.randint(len(train_data)) \n",
    "    c = np.random.randint(6) \n",
    "    train_data.iloc[r, c] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "age         2\n",
       "sex         1\n",
       "bmi         1\n",
       "children    3\n",
       "smoker      1\n",
       "region      2\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop('charges', 1), \n",
    "                                                    train_data['charges'], \n",
    "                                                    test_size = 0.2, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf1 = ColumnTransformer(transformers =[ \n",
    "    ('cat', SimpleImputer(strategy ='most_frequent'), ['sex', 'smoker', 'region']), \n",
    "    ('num', SimpleImputer(strategy ='median'), ['age', 'bmi', 'children']), \n",
    "      \n",
    "], remainder ='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['male', 'yes', 'southwest', 37.0, 34.1, 4.0],\n",
       "       ['male', 'no', 'southeast', 18.0, 34.43, 0.0],\n",
       "       ['female', 'yes', 'northeast', 23.0, 36.67, 2.0],\n",
       "       ...,\n",
       "       ['male', 'no', 'southeast', 40.0, 25.08, 1.0],\n",
       "       ['male', 'no', 'northwest', 19.0, 35.53, 0.0],\n",
       "       ['female', 'no', 'southeast', 33.0, 18.5, 1.0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "first_step = trf1.fit_transform(X_train) \n",
    "first_step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        0    1          2   3       4  5\n",
       "0    male  yes  southwest  37    34.1  4\n",
       "1    male   no  southeast  18   34.43  0\n",
       "2  female  yes  northeast  23   36.67  2\n",
       "3    male   no  southwest  32    35.2  2\n",
       "4  female   no  northeast  58  32.395  1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>yes</td>\n      <td>southwest</td>\n      <td>37</td>\n      <td>34.1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>male</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>18</td>\n      <td>34.43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>yes</td>\n      <td>northeast</td>\n      <td>23</td>\n      <td>36.67</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>male</td>\n      <td>no</td>\n      <td>southwest</td>\n      <td>32</td>\n      <td>35.2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>female</td>\n      <td>no</td>\n      <td>northeast</td>\n      <td>58</td>\n      <td>32.395</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "pd.DataFrame(first_step).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cat': SimpleImputer(strategy='most_frequent'),\n",
       " 'num': SimpleImputer(strategy='median')}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "trf1.named_transformers_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([39. , 30.4,  1. ])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# these were the median values of each of the three numerical columns. \n",
    "# for any transformer, you can access its specific attributes this way.\n",
    "trf1.named_transformers_['num'].statistics_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: OneHotEncoder can’t handle missing values, hence it is important to get rid of them before encoding. Now, we make another transformer object for the encoding. We couldn’t do this in ‘trf1’ because at that point in time, there were missing values in the X_train, and OneHotEncoder can’t deal with missing values as discussed earlier. Hence we first needed to remove the missing values, and then pass this new ‘first_step’ array (with no missing values) to OneHotEncoder.\n",
    "\n",
    "#We set the sparse parameter to False (because we want a dense array output) and we can toggle between dropping the first of the dummy encoded columns or not, depending upon the type of model we’re fitting, to avoid the ‘dummy variable trap’. Learn more about it here: A general rule of thumb: drop a dummy-encoded column if using a linear-based model, and do not drop it if using a tree-based model. Also, did you see how for the columns parameter, we specified list(range(3)) instead of the column names? That is because now, we’ve lost the column names (as seen in ‘first_step’, but we know the categorical columns are the first three columns (after reordering), hence we specify [0, 1, 2].\n",
    "trf2 = ColumnTransformer(transformers =[ \n",
    "    ('enc', OneHotEncoder(sparse = False, drop ='first'), list(range(3))), \n",
    "], remainder ='passthrough') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps =[ \n",
    "    ('tf1', trf1), \n",
    "    ('tf2', trf2), \n",
    "    ('tf3', StandardScaler()), # or StandardScaler, or any other scaler \n",
    "    ('model', RandomForestRegressor(n_estimators = 200)), \n",
    "# or LinearRegression, SVR, DecisionTreeRegressor, etc \n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All cross val scores: [0.85782059 0.81670185 0.80040809 0.81790831 0.76733147]\nMean of all scores:  0.8120340616469687\n"
     ]
    }
   ],
   "source": [
    "cvs = cross_val_score(pipe, X_train, y_train, cv = 5) \n",
    "print(\"All cross val scores:\", cvs) \n",
    "print(\"Mean of all scores: \", cvs.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf1',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('cat',\n",
       "                                                  SimpleImputer(strategy='most_frequent'),\n",
       "                                                  ['sex', 'smoker', 'region']),\n",
       "                                                 ('num',\n",
       "                                                  SimpleImputer(strategy='median'),\n",
       "                                                  ['age', 'bmi',\n",
       "                                                   'children'])])),\n",
       "                ('tf2',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('enc',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                sparse=False),\n",
       "                                                  [0, 1, 2])])),\n",
       "                ('tf3', StandardScaler()),\n",
       "                ('model', RandomForestRegressor(n_estimators=200))])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      original test set   predictions\n",
       "578          9724.53000  10648.232822\n",
       "610          8547.69130   9887.297975\n",
       "569         45702.02235  44485.007832\n",
       "1034        12950.07120  13208.181387\n",
       "198          9644.25250  10054.271969\n",
       "...                 ...           ...\n",
       "1084        15019.76005  15878.597914\n",
       "726          6664.68595   6617.496041\n",
       "1132        20709.02034  11295.988688\n",
       "725         40932.42950  43049.301895\n",
       "963          9500.57305   9510.482217\n",
       "\n",
       "[268 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original test set</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>578</th>\n      <td>9724.53000</td>\n      <td>10648.232822</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>8547.69130</td>\n      <td>9887.297975</td>\n    </tr>\n    <tr>\n      <th>569</th>\n      <td>45702.02235</td>\n      <td>44485.007832</td>\n    </tr>\n    <tr>\n      <th>1034</th>\n      <td>12950.07120</td>\n      <td>13208.181387</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>9644.25250</td>\n      <td>10054.271969</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1084</th>\n      <td>15019.76005</td>\n      <td>15878.597914</td>\n    </tr>\n    <tr>\n      <th>726</th>\n      <td>6664.68595</td>\n      <td>6617.496041</td>\n    </tr>\n    <tr>\n      <th>1132</th>\n      <td>20709.02034</td>\n      <td>11295.988688</td>\n    </tr>\n    <tr>\n      <th>725</th>\n      <td>40932.42950</td>\n      <td>43049.301895</td>\n    </tr>\n    <tr>\n      <th>963</th>\n      <td>9500.57305</td>\n      <td>9510.482217</td>\n    </tr>\n  </tbody>\n</table>\n<p>268 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "pd.DataFrame({'original test set':y_test, 'predictions': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}